# Reqvolt — Cursor AI Build Prompts

## Gap Closure: From Current Build to Full Platform

**SynqForge LTD | February 2026**

These prompts are designed for **Cursor AI** (Composer or Agent mode) working against the existing Reqvolt codebase. Each prompt assumes the previous prompts have been successfully implemented. They follow the project's established conventions: tRPC + Zod, workspaceProcedure with workspaceId scoping, Prisma 6 with Neon, Inngest background jobs, UK English throughout, and audit logging on all mutations.

### How to Use

1. Open Cursor in the Reqvolt project root.
2. Feed one prompt at a time into Composer (Agent mode recommended).
3. Point Cursor at the relevant `docs/` files and existing routers/services as context.
4. Run `pnpm verify` after each prompt to confirm lint + typecheck + test + build pass.
5. Commit with the branch/message format specified in each prompt.
6. Test the acceptance criteria before moving to the next prompt.

### Context Files to Always Include

When feeding a prompt, always attach these files in Cursor's context panel:

- `CLAUDE.md` (project rules)
- `docs/BUILD_INSTRUCTIONS.md` (coding standards)
- `docs/DATA_MODEL.md` (schema reference)
- `prisma/schema.prisma` (current schema)

Plus the specific files referenced in each prompt's "Context Files" section.

---

## Prompt 1: Additional Export Formats (CSV, HTML Client Pack, JSON)

**Branch:** `phase-2/story-S5.2-additional-export-formats`
**Commit prefix:** `feat(S5.2):`

### Context Files
- `src/server/routers/pack.ts`
- `src/server/services/docx-export.ts`
- `src/app/api/packs/[packId]/versions/[versionId]/export/route.ts`

### Prompt — Copy into Cursor Composer

```
Read docs/BUILD_INSTRUCTIONS.md and docs/DATA_MODEL.md first.

The existing Reqvolt codebase has a DOCX export at src/server/services/docx-export.ts and an API route at src/app/api/packs/[packId]/versions/[versionId]/export/route.ts. I need three additional export formats. All must follow existing patterns: workspaceId scoping, UK English, TypeScript strict, no `any` types.

1. **CSV Export** — new service at src/server/services/csv-export.ts
   - Columns: artefact_type, id, title, description, acceptance_criteria (pipe-separated given/when/then), priority, status, evidence_sources
   - Use a lightweight CSV builder (no heavy dependencies — template literals or a small lib like csv-stringify)
   - Include a metadata header row: pack name, project name, generation date, source list
   - Return a Buffer with UTF-8 BOM for Excel compatibility

2. **HTML Client Pack** — new service at src/server/services/html-export.ts
   - Generates a self-contained HTML file (inline CSS, no external deps) that can be opened in a browser or printed to PDF
   - Professional header: project name, client name (from project.description or a clientName field), pack name, generation date
   - Table of contents linking to each artefact type section (Epics, Stories, NFRs, Assumptions, Risks, Decisions)
   - All artefacts rendered with clean formatting: stories show persona/want/soThat, ACs show given/when/then as a checklist
   - Evidence coverage badge per story (green if ≥1 evidence link, red if zero)
   - QA summary section at the bottom (pass/warn/fail counts)
   - Footer: "Generated by Reqvolt" with timestamp
   - Use Reqvolt brand colours: dark navy (#1B2A4A) headers, teal (#0D8B8B) accents, white backgrounds
   - Return a Buffer of the HTML string

3. **JSON Export** — new service at src/server/services/json-export.ts
   - Full pack data structure as JSON: pack metadata, all stories with ACs, evidence links, QA flags, health score
   - Include a `_meta` object: { exportedAt, packVersion, sourceIds, reqvoltVersion: "1.0" }
   - Return a Buffer of the JSON string

4. **Update the export API route** at src/app/api/packs/[packId]/versions/[versionId]/export/route.ts:
   - Accept a `format` query parameter: "docx" (default), "csv", "html", "json"
   - Set correct Content-Type and Content-Disposition headers for each format
   - Validate workspaceId access before export
   - Log to AuditLog: action "pack_exported", metadata: { format, packId, versionId }

5. **Update the pack editor UI** — in the export button/dropdown in src/components/pack-editor/:
   - Change the single export button to a dropdown with four options: Word Document, CSV Spreadsheet, Client Pack (HTML), JSON Data
   - Each option triggers the same export endpoint with the appropriate format parameter

6. **Add a "Copy to Clipboard" button** next to each story in the pack editor that copies the story as formatted markdown (persona/want/soThat + AC checklist)

7. **Tests:**
   - src/tests/server/services/csv-export.test.ts — verify column structure, pipe-separated ACs, UTF-8 BOM
   - src/tests/server/services/html-export.test.ts — verify HTML contains TOC, all artefact sections, footer
   - src/tests/server/services/json-export.test.ts — verify _meta object, all stories included

Run pnpm verify when done.
```

### Test Before Moving On
- Download each format and verify content is complete and correctly structured
- Open the HTML export in a browser — does it look professional with Reqvolt branding?
- Does the CSV open correctly in Excel with proper columns?
- Does the JSON parse cleanly and include all stories with evidence links?
- Does the clipboard copy produce well-formatted markdown?

---

## Prompt 2: Evidence Ledger — Standalone View with Classification Tags

**Branch:** `phase-2/story-S6.1-evidence-ledger-view`
**Commit prefix:** `feat(S6.1):`

### Context Files
- `prisma/schema.prisma` (SourceChunk model)
- `src/server/routers/source.ts`
- `src/server/services/retrieval.ts`
- `src/app/(dashboard)/workspace/[workspaceId]/projects/[projectId]/page.tsx`

### Prompt — Copy into Cursor Composer

```
Read docs/BUILD_INSTRUCTIONS.md and docs/DATA_MODEL.md first.

The existing codebase has SourceChunk records that store chunked source content with pgvector embeddings. These are created by the Inngest chunk-and-embed job. I need to add an Evidence Ledger as a standalone view with AI-powered classification.

1. **Schema changes** — add to prisma/schema.prisma:
   - Add a `classificationTag` enum: REQUIREMENT, DECISION, COMMITMENT, QUESTION, CONTEXT, CONSTRAINT
   - Add a `classificationTag` field to the SourceChunk model (nullable, defaults to null for existing records)
   - Add a `classificationConfidence` Float? field to SourceChunk
   - Run: npx prisma migrate dev --name add-evidence-classification

2. **Classification service** — new file src/server/services/evidence-classification.ts:
   - Export async function classifyChunks(chunks: { id: string, content: string }[]): Promise<ClassificationResult[]>
   - Use the Anthropic Claude API (import from existing model-router.ts pattern) to classify each chunk
   - Batch chunks in groups of 20 to reduce API calls
   - System prompt: "You are classifying source evidence chunks for requirements engineering. For each chunk, assign exactly one tag: REQUIREMENT (a stated need or capability), DECISION (a choice that has been made), COMMITMENT (a promise or agreement), QUESTION (an unresolved query), CONTEXT (background information), CONSTRAINT (a limitation or boundary). Return JSON array with { chunkId, tag, confidence }."
   - Store results back to SourceChunk records
   - If classification fails, leave classificationTag as null (graceful degradation)

3. **Update the Inngest chunk-and-embed job** at src/server/inngest/chunk-and-embed.ts:
   - After embedding is complete, call classifyChunks() for the new chunks
   - This runs asynchronously so it won't block the ingestion pipeline

4. **Evidence Ledger tRPC router** — new file src/server/routers/evidence-ledger.ts:
   - `list` query: returns all SourceChunks for a project, with filters:
     - sourceId (optional) — filter by specific source
     - classificationTag (optional) — filter by tag
     - dateRange (optional) — { from: Date, to: Date }
     - search (optional) — full-text search on chunk content
     - Pagination: cursor-based with limit (default 50)
     - Always scoped to workspaceId via the project
     - Include parent Source name and type
     - Include count of linked EvidenceLinks per chunk
   - `stats` query: returns counts per classification tag for a project
   - `reclassify` mutation: re-run classification on all chunks for a source (manual trigger)
   - Register in src/server/routers/_app.ts

5. **Evidence Ledger page** — new route:
   - src/app/(dashboard)/workspace/[workspaceId]/projects/[projectId]/evidence/page.tsx
   - Summary cards at the top: one card per classification tag showing count (like the prompt pack describes)
   - Filterable list below: filter by source, classification tag, date range
   - Search bar for full-text search across evidence text
   - Each evidence item shows: truncated chunk text (150 chars), source name, classification badge (coloured by tag), date, linked artefact count
   - Click an evidence item to expand: full chunk text, "View in Source" link that navigates to the source with the chunk highlighted
   - Use existing shadcn/ui components (Badge, Card, Input, Select)

6. **Navigation update:**
   - Add "Evidence" link in the project sidebar navigation, positioned between Sources and Packs
   - Show evidence count badge in the nav item

7. **Update source detail view:**
   - When viewing a source's content, show the extracted evidence items below with classification badges
   - Each chunk highlighted or annotated within the source context

8. **Tests:**
   - src/tests/server/services/evidence-classification.test.ts — test classification with mocked Anthropic response
   - src/tests/server/routers/evidence-ledger.test.ts — test list query with filters, stats query

Run pnpm verify when done.
```

### Test Before Moving On
- Upload a document with clear decisions and requirements — are they extracted as separate evidence items with reasonable classification tags?
- Can you filter the ledger by classification type?
- Does the search work across evidence text?
- Can you click through from an evidence item to see it in the source context?
- Do the summary cards show correct counts?

---

## Prompt 3: Source Conflict Detection

**Branch:** `phase-2/story-S8.1-conflict-detection`
**Commit prefix:** `feat(S8.1):`

### Context Files
- `prisma/schema.prisma`
- `src/server/services/retrieval.ts`
- `src/server/services/embedding.ts`
- `src/server/routers/evidence-ledger.ts` (from Prompt 2)

### Prompt — Copy into Cursor Composer

```
Read docs/BUILD_INSTRUCTIONS.md and docs/DATA_MODEL.md first.

Add conflict detection between source evidence items. When two chunks from different sources contradict each other, the system should flag this.

1. **Schema changes** — add to prisma/schema.prisma:

   model EvidenceConflict {
     id              String   @id @default(cuid())
     workspaceId     String
     projectId       String
     chunkAId        String
     chunkBId        String
     conflictSummary String   // AI-generated explanation of the contradiction
     confidence      Float    // 0.0 to 1.0
     resolution      ConflictResolution? @default(unresolved)
     resolvedBy      String?  // userId
     resolvedAt      DateTime?
     resolutionNote  String?
     createdAt       DateTime @default(now())
     updatedAt       DateTime @updatedAt

     chunkA    SourceChunk @relation("ConflictChunkA", fields: [chunkAId], references: [id], onDelete: Cascade)
     chunkB    SourceChunk @relation("ConflictChunkB", fields: [chunkBId], references: [id], onDelete: Cascade)
     project   Project     @relation(fields: [projectId], references: [id], onDelete: Cascade)

     @@index([projectId])
     @@index([workspaceId])
     @@unique([chunkAId, chunkBId])
   }

   enum ConflictResolution {
     unresolved
     source_a_preferred
     source_b_preferred
     both_valid
     dismissed
   }

   Add the reverse relations to SourceChunk and Project models.
   Run: npx prisma migrate dev --name add-evidence-conflicts

2. **Conflict detection service** — new file src/server/services/conflict-detection.ts:
   - Export async function detectConflicts(projectId: string, workspaceId: string): Promise<EvidenceConflict[]>
   - Strategy:
     a) Use pgvector similarity to find semantically similar chunks from DIFFERENT sources (cosine similarity > 0.85)
     b) For each pair of similar chunks, send to Claude API with prompt: "These two text excerpts are from different source documents in the same project. Determine if they contradict each other. If they do, explain the contradiction briefly. Return JSON: { contradicts: boolean, summary: string, confidence: number }."
     c) If contradicts=true, create an EvidenceConflict record
   - Batch processing: process pairs in groups of 10 to manage API costs
   - Skip pairs where a conflict already exists (idempotent)
   - Return newly created conflicts

3. **Inngest job** — new file src/server/inngest/detect-conflicts.ts:
   - Function name: "reqvolt/detect-source-conflicts"
   - Triggered after chunk-and-embed completes (chain from existing job)
   - Also triggerable manually via tRPC mutation
   - Calls detectConflicts() for the project
   - Sends notification if new conflicts found (use existing notifications service)

4. **Update evidence-ledger router** (src/server/routers/evidence-ledger.ts):
   - Add `conflicts` query: list all EvidenceConflicts for a project, include chunkA and chunkB with their source names
   - Add `resolveConflict` mutation: update resolution, resolvedBy, resolvedAt, resolutionNote. Log to AuditLog.
   - Add `triggerConflictDetection` mutation: manually trigger the Inngest job

5. **Conflicts UI** — add to the Evidence Ledger page:
   - New "Conflicts" tab alongside the main evidence list
   - Each conflict shows: both chunk texts side by side, source names, AI-generated conflict summary, confidence score
   - Resolution buttons: "Prefer Source A", "Prefer Source B", "Both Valid", "Dismiss"
   - Resolution requires a note field
   - Show conflict count badge on the Evidence nav item (unresolved only)
   - Conflict count card in the Source Health summary on the project dashboard

6. **Tests:**
   - src/tests/server/services/conflict-detection.test.ts — test with mocked embeddings and API responses
   - Test idempotency (running twice doesn't create duplicate conflicts)

Run pnpm verify when done.
```

### Test Before Moving On
- Upload two documents with contradictory statements — does the conflict detection find them?
- Can you see both chunks side by side in the conflicts view?
- Can you resolve a conflict with a note and see the resolution recorded?
- Does running detection again skip already-detected conflicts?

---

## Prompt 4: Formal Approval Workflow with Sign-Off

**Branch:** `phase-3/story-S11.1-formal-approvals`
**Commit prefix:** `feat(S11.1):`

### Context Files
- `prisma/schema.prisma`
- `src/server/routers/pack.ts`
- `src/app/(dashboard)/workspace/[workspaceId]/projects/[projectId]/packs/[packId]/page.tsx`
- `src/app/review/[token]/page.tsx`

### Prompt — Copy into Cursor Composer

```
Read docs/BUILD_INSTRUCTIONS.md, docs/DATA_MODEL.md, and docs/USER_FLOWS.md first.

Add a formal approval workflow to packs. This extends the existing review link system.

1. **Schema changes** — add to prisma/schema.prisma:

   model ApprovalRequest {
     id              String   @id @default(cuid())
     workspaceId     String
     packId          String
     packVersionId   String
     approverName    String
     approverEmail   String
     approvalScope   ApprovalScope @default(full_pack)
     scopeFilter     Json?    // e.g. { artefactTypes: ["story", "nfr"] } for scoped approvals
     token           String   @unique @default(cuid())
     dueDate         DateTime?
     status          ApprovalRequestStatus @default(pending)
     approvedAt      DateTime?
     signatureName   String?  // Typed name as digital signature
     rejectionReason String?
     createdAt       DateTime @default(now())
     updatedAt       DateTime @updatedAt

     pack        Pack        @relation(fields: [packId], references: [id], onDelete: Cascade)
     packVersion PackVersion @relation(fields: [packVersionId], references: [id], onDelete: Cascade)

     @@index([packId])
     @@index([workspaceId])
     @@index([token])
   }

   enum ApprovalScope { full_pack, scoped }
   enum ApprovalRequestStatus { pending, approved, changes_requested, expired }

   Add reverse relations to Pack and PackVersion.
   Run: npx prisma migrate dev --name add-approval-requests

2. **Approval router** — new file src/server/routers/approval.ts:
   - `list` query: all approval requests for a pack, scoped to workspaceId
   - `create` mutation: create approval request, generate token, send email notification (use existing email service). Log to AuditLog.
   - `revoke` mutation: delete a pending approval request. Log to AuditLog.
   - Register in src/server/routers/_app.ts

3. **Public approval endpoint** — new API route at src/app/api/approvals/[token]/route.ts:
   - GET: return pack data for the approval token (read-only view, no auth required), include reviewer comments
   - POST: accept approval action: { action: "approve" | "request_changes", signatureName?: string, comments?: string }
     - "approve": set status to approved, store signatureName and approvedAt
     - "request_changes": set status to changes_requested, store rejectionReason, create ReviewComment records
   - Validate token exists and is not expired (dueDate check)
   - After action: check if ALL approval requests for the pack are now "approved" — if so, update pack reviewStatus to "approved"
   - Log to AuditLog with action "pack_approval_recorded"

4. **Approval page** — new route at src/app/approve/[token]/page.tsx:
   - Read-only pack view (similar to review page but with approval controls)
   - Shows all artefacts organised by type with evidence coverage indicators
   - "Approve" button: opens confirmation dialog requiring typed signature name
   - "Request Changes" button: opens comment form
   - Show approval scope (full pack or specific artefact types)
   - Show due date if set

5. **Update pack editor UI:**
   - Add "Approvals" section in the pack detail view (new tab or panel)
   - "Request Approval" button: form to enter approver name, email, scope, due date
   - List of approval requests with status badges (pending/approved/changes requested)
   - Approval history timeline showing all approval actions with timestamps
   - When all approvals are "approved", show a prominent "Pack Approved" banner

6. **Sign-Off Pack export:**
   - Add a "Download Sign-Off Pack" button (only visible when pack status is "approved")
   - Extends the existing DOCX export to include:
     - Approval records section: approver names, timestamps, scopes, digital signatures
     - QA summary section
     - Evidence coverage summary
   - This is a formal deliverable for client sign-off

7. **Tests:**
   - src/tests/server/routers/approval.test.ts — create, approve, request changes, auto-status-update
   - Test token expiry logic
   - Test auto-promotion to "approved" when all requests are approved

Run pnpm verify when done.
```

### Test Before Moving On
- Can you create an approval request and receive the link?
- Can the approver open the link and approve with a typed signature?
- Does the pack status change to "approved" when all approvals are recorded?
- Can you download the sign-off pack with approval records?
- Does "Request Changes" correctly store comments?

---

## Prompt 5: Immutable Baseline Snapshots with Diff Comparison

**Branch:** `phase-3/story-S12.1-baseline-snapshots`
**Commit prefix:** `feat(S12.1):`

### Context Files
- `prisma/schema.prisma` (PackVersion model)
- `src/server/routers/pack.ts`
- `src/server/services/health.ts`
- `src/lib/diff.ts` (if it exists)

### Prompt — Copy into Cursor Composer

```
Read docs/BUILD_INSTRUCTIONS.md, docs/DATA_MODEL.md, and docs/USER_FLOWS.md first.

Add immutable baseline snapshots and diff comparison to packs. A baseline is a frozen snapshot of a pack at a point in time that cannot be edited.

1. **Schema changes** — add to prisma/schema.prisma:

   model Baseline {
     id              String   @id @default(cuid())
     workspaceId     String
     packId          String
     packVersionId   String
     versionLabel    String   // "Baseline v1", "Baseline v2", auto-incremented
     versionNumber   Int      // 1, 2, 3...
     snapshotData    Json     // Complete frozen snapshot of pack content
     approvalRef     String?  // Reference to approval that triggered baseline
     note            String?
     createdBy       String   // userId
     createdAt       DateTime @default(now())

     pack        Pack        @relation(fields: [packId], references: [id], onDelete: Cascade)
     packVersion PackVersion @relation(fields: [packVersionId], references: [id], onDelete: Cascade)

     @@index([packId])
     @@index([workspaceId])
   }

   Add a `lastBaselineId` String? field to Pack model (FK to Baseline).
   Add a `divergedFromBaseline` Boolean @default(false) field to Pack model.
   Add reverse relations.
   Run: npx prisma migrate dev --name add-baselines

2. **Baseline service** — new file src/server/services/baseline.ts:
   - Export async function createBaseline(packId: string, workspaceId: string, userId: string, note?: string): Promise<Baseline>
     - Load the full pack with all stories, ACs, evidence links, QA flags, health score
     - Serialize to a JSON snapshot (snapshotData): { stories: [...], evidenceLinks: [...], qaFlags: [...], healthScore, sources: [...] }
     - Auto-increment versionNumber (query max existing + 1)
     - Generate versionLabel: "Baseline v{N}"
     - Store snapshot and update pack.lastBaselineId
     - Reset pack.divergedFromBaseline to false
   - Export async function compareBaselines(baselineAId: string, baselineBId: string): Promise<BaselineDiff>
     - Parse both snapshotData JSON objects
     - Compute diff: added stories, removed stories, modified stories (compare title, persona, want, soThat, ACs)
     - For modified stories: show field-level changes (what changed)
     - Changed evidence links: added/removed links
     - Return structured diff object

3. **Divergence tracking:**
   - In the pack router's update mutations (story edit, AC edit, story add/delete), after each mutation:
     - If pack.lastBaselineId is not null, set pack.divergedFromBaseline = true
   - This is a lightweight check, not a deep comparison

4. **Baseline router** — new file src/server/routers/baseline.ts:
   - `list` query: all baselines for a pack, ordered by versionNumber desc. Scoped to workspaceId.
   - `getSnapshot` query: return a specific baseline's snapshotData (the frozen pack view)
   - `create` mutation: call createBaseline(). Only allowed if pack.reviewStatus is "approved". Log to AuditLog.
   - `compare` query: compare two baselines by ID, return the diff
   - Register in src/server/routers/_app.ts

5. **Baseline UI:**
   - Add "Baselines" tab in the pack detail view
   - "Create Baseline" button (only enabled when pack status is "approved")
   - Timeline view of all baselines: version label, date, created by, note
   - Click a baseline to view the frozen snapshot (read-only pack view from snapshotData)
   - "Compare" button: select two baselines from dropdowns, show diff view
   - Diff view: green highlighting for additions, red for removals, amber for modifications
   - Show field-level changes for modified stories (e.g., "Title changed from X to Y")

6. **Divergence indicator:**
   - In the pack header, show a warning badge when divergedFromBaseline is true: "Pack has changed since Baseline vN"
   - Include a "View changes since baseline" link that compares current pack state to last baseline

7. **Tests:**
   - src/tests/server/services/baseline.test.ts — create baseline, verify snapshot structure, compare two baselines
   - Test divergence flag is set on story edit, reset on new baseline

Run pnpm verify when done.
```

### Test Before Moving On
- Create a baseline from an approved pack — does it show in the timeline?
- Edit a story after baseline — does the divergence indicator appear?
- Create a second baseline — can you compare the two and see the diff?
- Is the original baseline snapshot truly immutable (read-only)?
- Does the diff correctly highlight added, removed, and modified stories?

---

## Prompt 6: Change Request Entity with Approval Gates

**Branch:** `phase-3/story-S13.1-change-requests`
**Commit prefix:** `feat(S13.1):`

### Context Files
- `prisma/schema.prisma`
- `src/server/routers/source-impact.ts`
- `src/server/services/baseline.ts` (from Prompt 5)
- `src/server/inngest/detect-source-changes.ts`

### Prompt — Copy into Cursor Composer

```
Read docs/BUILD_INSTRUCTIONS.md and docs/DATA_MODEL.md first.

Add a formal Change Request system that links source changes to impacted artefacts and requires approval before editing.

1. **Schema changes** — add to prisma/schema.prisma:

   model ChangeRequest {
     id              String   @id @default(cuid())
     workspaceId     String
     projectId       String
     packId          String
     title           String
     description     String
     trigger         String   // Which source change triggered this
     triggerSourceId String?
     impactedStoryIds Json    // Array of story IDs affected
     impactSummary   String   // AI-generated summary of what changed and why
     requestedBy     String   // userId
     status          ChangeRequestStatus @default(open)
     approvedBy      String?
     approvedAt      DateTime?
     rejectionReason String?
     createdAt       DateTime @default(now())
     updatedAt       DateTime @updatedAt

     project Project @relation(fields: [projectId], references: [id], onDelete: Cascade)
     pack    Pack    @relation(fields: [packId], references: [id], onDelete: Cascade)

     @@index([projectId])
     @@index([packId])
     @@index([workspaceId])
   }

   enum ChangeRequestStatus { open, approved, rejected, implemented }

   Add reverse relations to Project and Pack.
   Run: npx prisma migrate dev --name add-change-requests

2. **Update source impact detection:**
   - In src/server/inngest/detect-source-changes.ts, after detecting impacts:
     - If a baseline exists for the affected pack, automatically create a draft ChangeRequest with:
       - title: "Source update: {sourceName}"
       - description: auto-generated from the SourceChangeImpact records
       - impactedStoryIds: array of affected story IDs
       - impactSummary: AI-generated summary using the existing impact analysis
       - status: open
     - Send notification to workspace members about the new CR

3. **Change request router** — new file src/server/routers/change-request.ts:
   - `list` query: all CRs for a project, scoped to workspaceId. Include pack name, story count.
   - `getById` query: single CR with full details including impacted story details
   - `create` mutation: manually create a CR (for cases not triggered by source changes). Log to AuditLog.
   - `approve` mutation: set status to approved, store approvedBy/approvedAt. Log to AuditLog.
     - When approved: mark the impacted stories as "unlocked for editing" (could be a `lockedByBaseline` boolean on Story that gets set to false)
   - `reject` mutation: set status to rejected with reason. Log to AuditLog.
   - `markImplemented` mutation: after edits are complete, mark as implemented. Log to AuditLog.
   - Register in src/server/routers/_app.ts

4. **Change Impact Report view:**
   - New component: src/components/change-request/ChangeImpactReport.tsx
   - Summary header: "X sources changed, Y evidence items affected, Z stories impacted"
   - Drill-down list organised by story: each story shows the evidence changes that affect it
   - "Requires re-approval" flag on stories whose evidence has changed since baseline
   - "Create Change Request" button that pre-fills from the impact analysis

5. **Change Request UI:**
   - Add "Change Requests" section accessible from the project page
   - List view: title, status badge, impacted story count, date, requested by
   - Detail view: full description, impact summary, list of impacted stories (clickable), approval buttons
   - For approved CRs: "Impacted stories are now editable" message
   - For rejected CRs: show rejection reason
   - Track edits made after CR approval for the next baseline comparison

6. **Update pack editor:**
   - Show a "Source Change Impact" banner at the top of the pack editor when there are unresolved source changes
   - Banner links to the Change Impact Report
   - Stories affected by source changes get an amber warning icon

7. **Tests:**
   - src/tests/server/routers/change-request.test.ts — CRUD, approve, reject flows
   - Test auto-creation from source impact detection

Run pnpm verify when done.
```

### Test Before Moving On
- Create a baseline, then upload a new version of a source — does a Change Request auto-create?
- Does the impact report correctly identify affected stories?
- Can you approve a CR and then edit the impacted stories?
- Does rejecting a CR with a reason display correctly?

---

## Prompt 7: Integration Sync Dashboard and Re-Push

**Branch:** `phase-4/story-S16.1-integration-dashboard`
**Commit prefix:** `feat(S16.1):`

### Context Files
- `src/server/routers/monday.ts`
- `src/server/routers/story-export.ts`
- `src/server/routers/jira.ts`
- `src/server/services/monday.ts`
- `src/server/services/jira.ts`
- `src/app/(dashboard)/workspace/[workspaceId]/settings/monday-settings/page.tsx`

### Prompt — Copy into Cursor Composer

```
Read docs/BUILD_INSTRUCTIONS.md, docs/DATA_MODEL.md, and docs/INTEGRATIONS.md first.

Add an Integration Dashboard that shows sync status across Monday.com and Jira, and a selective re-push feature.

1. **Update StoryExport model** — add to prisma/schema.prisma:
   - Add `changedSincePush` Boolean @default(false) to StoryExport
   - Run: npx prisma migrate dev --name add-changed-since-push

2. **Track post-push changes:**
   - In pack router story/AC update mutations:
     - After a story or AC is updated, check if a StoryExport exists for that story
     - If yes, set changedSincePush = true
   - This is a lightweight flag, not a deep diff

3. **Integration dashboard router** — update src/server/routers/story-export.ts (or create new src/server/routers/integration-dashboard.ts):
   - `syncStatus` query: for a given pack, return:
     - totalArtefacts: count of stories in pack
     - pushedToMonday: count with mondayItemId
     - pushedToJira: count with jiraIssueKey
     - notYetPushed: count with no external ID
     - changedSincePush: count where changedSincePush = true
   - `syncMap` query: for a given pack, return a table:
     - Each story: { storyId, title, mondayItemId, jiraIssueKey, lastPushDate, changedSincePush }
   - `pushHistory` query: all StoryExport records for a project, ordered by date desc, with: date, pack name, target system, artefact count, error count
   - `rePushChanged` mutation: for a given pack and target (monday/jira):
     - Find all StoryExports where changedSincePush = true
     - For each: update the existing Monday item / Jira issue (not create new)
     - Reset changedSincePush to false on success
     - Log to AuditLog with action "stories_repushed"
   - Register any new routers in src/server/routers/_app.ts

4. **Integration Dashboard page:**
   - New tab in project view: "Integrations"
   - Connection status cards: Monday.com and Jira with connected/disconnected status, last tested date
   - "Test Connection" button for each
   - Push history table: date, pack name, target system, artefacts pushed, issues created, errors
   - Per-pack sync status summary cards
   - Artefact sync map table: Reqvolt ID, title, Monday item ID (clickable link), Jira key (clickable link), last push date, "changed since push" flag
   - "Re-push Changed" button (only enabled when changedSincePush count > 0)
   - Clear messaging: "Reqvolt is the source of truth for content and evidence. Monday.com and Jira are execution systems."

5. **Tests:**
   - src/tests/server/routers/integration-dashboard.test.ts — sync status counts, push history, re-push logic

Run pnpm verify when done.
```

### Test Before Moving On
- Does the sync status show correct counts for pushed/not pushed/changed?
- Does the sync map table show all stories with their external IDs?
- After editing a pushed story, does changedSincePush flag appear?
- Does re-push update existing items rather than creating new ones?

---

## Prompt 8: Granular Project-Level RBAC (4 Roles)

**Branch:** `phase-5/story-S18.1-project-rbac`
**Commit prefix:** `feat(S18.1):`

### Context Files
- `prisma/schema.prisma` (WorkspaceMember model, WorkspaceRole enum)
- `src/server/trpc.ts` (middleware)
- `src/server/routers/workspace.ts`

### Prompt — Copy into Cursor Composer

```
Read docs/BUILD_INSTRUCTIONS.md and docs/DATA_MODEL.md first.

The current codebase has workspace-level roles (Admin, Member). Add project-level RBAC with four roles: Contributor, Reviewer, Viewer, Approver.

1. **Schema changes** — add to prisma/schema.prisma:

   model ProjectMember {
     id          String      @id @default(cuid())
     projectId   String
     userId      String
     role        ProjectRole @default(Viewer)
     assignedBy  String      // userId who assigned the role
     createdAt   DateTime    @default(now())
     updatedAt   DateTime    @updatedAt

     project Project @relation(fields: [projectId], references: [id], onDelete: Cascade)

     @@unique([projectId, userId])
     @@index([projectId])
     @@index([userId])
   }

   enum ProjectRole {
     Contributor  // create/edit sources, generate packs, edit artefacts, run QA
     Reviewer     // view all, add comments, approve/reject, cannot edit artefacts
     Viewer       // read-only access to all project content
     Approver     // reviewer permissions + formal pack approval
   }

   Add reverse relation to Project.
   Run: npx prisma migrate dev --name add-project-roles

2. **Permission middleware** — update src/server/trpc.ts:
   - Create a new `projectProcedure` that extends `workspaceProcedure`:
     - Accepts projectId in input
     - Loads the user's ProjectMember record (or falls back to workspace Admin = full access)
     - Adds ctx.projectRole: ProjectRole | "admin" to the context
   - Create helper: `requireProjectRole(ctx, ...allowedRoles: (ProjectRole | "admin")[])`
     - Throws TRPCError("FORBIDDEN") if the user's role is not in the allowed list

3. **Enforce permissions in existing routers:**
   - Pack router mutations (generate, edit stories, add ACs, delete): require Contributor or admin
   - Pack router queries (list, getById): require any role
   - Review/comment mutations: require Reviewer, Approver, or admin
   - Approval mutations: require Approver or admin
   - Source mutations (upload, delete): require Contributor or admin
   - Baseline create: require Contributor or admin
   - Change request approve/reject: require Approver or admin
   - Export actions: require any role

4. **Project members router** — new file src/server/routers/project-member.ts:
   - `list` query: all members for a project with their roles
   - `assign` mutation: assign a workspace member to a project with a role. Log to AuditLog.
   - `updateRole` mutation: change a member's project role. Log to AuditLog.
   - `remove` mutation: remove a member from a project. Log to AuditLog.
   - Register in src/server/routers/_app.ts

5. **UI updates:**
   - Project settings page: add "Team" tab showing project members with role dropdowns
   - "Add Member" button: select from workspace members not yet assigned to this project
   - Role dropdown with descriptions: Contributor (can edit), Reviewer (can comment), Viewer (read only), Approver (can approve)
   - Disable/hide UI actions based on the user's project role:
     - Viewers see no edit buttons
     - Reviewers see comment buttons but no edit buttons
     - Contributors see all edit buttons but no approval buttons
     - Approvers see comment and approval buttons
   - Show role badge next to user names in comments and approval records

6. **Tests:**
   - src/tests/server/middleware/project-rbac.test.ts — test each role against each permission
   - Test that workspace Admin bypasses project roles
   - Test forbidden errors for insufficient permissions

Run pnpm verify when done.
```

### Test Before Moving On
- Assign a user as Viewer — can they see content but not edit?
- Assign as Reviewer — can they comment but not edit artefacts?
- Assign as Contributor — can they edit but not approve?
- Does a workspace Admin have full access regardless of project role?
- Do forbidden actions show a clear "Insufficient permissions" message?

---

## Prompt 9: Data Retention Policies and SAR Export

**Branch:** `phase-5/story-S20.1-data-retention`
**Commit prefix:** `feat(S20.1):`

### Context Files
- `prisma/schema.prisma`
- `src/server/routers/workspace.ts`
- `src/server/inngest/cleanup-old-data.ts`
- `src/server/services/audit.ts`

### Prompt — Copy into Cursor Composer

```
Read docs/BUILD_INSTRUCTIONS.md and docs/DATA_MODEL.md first.

Add data retention policies, deletion controls, and a SAR-ready data export to workspace settings.

1. **Schema changes** — add to prisma/schema.prisma:
   - Add to Workspace model:
     - retentionAutoArchiveDays  Int @default(180)
     - retentionAutoDeleteDays   Int @default(365)
     - retentionEnabled          Boolean @default(false)
   - Add to Project model:
     - archivedAt  DateTime?
     - deletedAt   DateTime?  // soft delete
     - exemptFromRetention Boolean @default(false)
   - Add to SourceChunk model (if not already present):
     - redactedAt  DateTime?
     - redactedBy  String?
   - Run: npx prisma migrate dev --name add-retention-policies

2. **Retention service** — new file src/server/services/retention.ts:
   - Export function applyRetentionPolicy(workspaceId: string): auto-archive projects inactive for > retentionAutoArchiveDays, set archivedAt
   - Export function purgeExpiredProjects(workspaceId: string): permanently delete projects where deletedAt is > retentionAutoDeleteDays ago (only if not exemptFromRetention)
   - Export function softDeleteProject(projectId: string): set deletedAt to now (30-day recovery window)
   - Export function recoverProject(projectId: string): clear deletedAt (only within 30-day window)
   - Export function redactEvidence(chunkId: string, userId: string): replace chunk content with "[REDACTED]", preserve link structure, set redactedAt/redactedBy
   - Export function exportAllProjectData(projectId: string, workspaceId: string): generates a ZIP containing:
     - sources/ — original uploaded files (from R2 presigned URLs)
     - evidence.json — all evidence items
     - packs.json — all packs with stories, ACs, evidence links
     - baselines.json — all baseline snapshots
     - audit-log.csv — all audit log entries for this project
     - manifest.json — { exportedAt, projectId, fileList, sha256Hashes }
   - Return the ZIP as a Buffer

3. **Update Inngest cleanup job** at src/server/inngest/cleanup-old-data.ts:
   - Add retention policy enforcement: run applyRetentionPolicy and purgeExpiredProjects for each workspace with retentionEnabled = true
   - Schedule: daily at 02:00 UTC

4. **Retention router** — add to src/server/routers/workspace.ts (or new file):
   - `getRetentionPolicy` query
   - `updateRetentionPolicy` mutation (workspace Admin only). Log to AuditLog.
   - `softDeleteProject` mutation: soft delete with impact warning (show affected packs, stories count). Log to AuditLog.
   - `recoverProject` mutation: recover within 30-day window. Log to AuditLog.
   - `purgeSource` mutation: permanently remove a source and all its evidence items (with impact warning showing affected artefacts). Log to AuditLog.
   - `redactEvidence` mutation: redact a single evidence item. Log to AuditLog.
   - `exportProjectData` mutation: trigger the ZIP export, return download URL
   - `exemptProject` mutation: toggle exemptFromRetention on a project

5. **UI updates in workspace settings:**
   - New "Data Governance" section:
     - Retention policy toggle (enable/disable)
     - Auto-archive days slider/input (default 180)
     - Auto-delete days slider/input (default 365)
     - List of projects with exemption toggles
   - "Data Summary" panel: total projects, total sources, total storage used, retention policy status
   - "Export All Data" button (per project) — downloads the SAR-ready ZIP
   - Delete project confirmation dialog: lists what will be permanently removed
   - Soft-deleted projects shown in a "Recently Deleted" section with "Recover" buttons and countdown to permanent deletion

6. **Redact UI:**
   - In the Evidence Ledger, each evidence item gets a "Redact" option in its action menu
   - Confirmation dialog: "This will replace the evidence text with [REDACTED]. The link structure will be preserved. This cannot be undone."
   - Redacted items show as "[REDACTED]" with the redaction date and user

7. **Tests:**
   - src/tests/server/services/retention.test.ts — auto-archive logic, soft delete, recovery, redaction, ZIP export structure

Run pnpm verify when done.
```

### Test Before Moving On
- Can you enable retention policies and set custom days?
- Does soft-deleting a project show it in "Recently Deleted" with a recover option?
- Does redacting an evidence item replace the text while preserving links?
- Does the ZIP export contain all expected files with correct content?
- Does the manifest include SHA-256 hashes?

---

## Prompt 10: Portfolio Analytics Dashboard

**Branch:** `phase-6/story-S21.1-portfolio-analytics`
**Commit prefix:** `feat(S21.1):`

### Context Files
- `src/server/routers/dashboard.ts`
- `src/server/services/health.ts`
- `src/components/dashboard/` (existing dashboard components)

### Prompt — Copy into Cursor Composer

```
Read docs/BUILD_INSTRUCTIONS.md and docs/DATA_MODEL.md first.

Add a Portfolio Analytics section to the workspace that provides cross-project metrics and risk signals.

1. **Portfolio analytics service** — new file src/server/services/portfolio-analytics.ts:

   Export async function getPortfolioMetrics(workspaceId: string, dateRange?: { from: Date, to: Date }):

   Compute and return:

   a) **Coverage metrics:**
      - averageEvidenceCoverage: average % of stories with ≥1 evidence link across all active packs
      - averageApprovalCoverage: % of packs with at least one approved ApprovalRequest
      - projectsWithNoBaseline: count and list of project names

   b) **Volatility metrics:**
      - baselineFrequency: per project, count of baselines created in date range
      - changeRequestVolume: { total, approved, rejected } CRs in date range
      - churnHotspots: top 5 packs by story edit count (use AuditLog action counts)

   c) **Cycle time metrics:**
      - avgSourceToGeneration: average days from first source upload to first pack generation per project
      - avgGenerationToBaseline: average days from pack generation to first baseline
      - avgBaselineToPush: average days from baseline to first integration push

   d) **Quality metrics:**
      - qaPassRate: % of stories passing all QA rules across all packs
      - commonQAFailures: top 5 QA rule codes by frequency (use QAFlag counts)
      - ambiguousWordTrend: count of VAGUE_TERM flags per month over last 6 months

   e) **Risk signals:**
      - unresolvedConflicts: count per project
      - lowCoveragePacks: packs with evidence coverage < 50%
      - orphanedStories: stories with zero evidence links
      - staleSources: sources not updated in 60+ days

2. **Portfolio router** — new file src/server/routers/portfolio.ts:
   - `metrics` query: calls getPortfolioMetrics, scoped to workspaceId
   - `projectBreakdown` query: per-project metrics table (project name, pack count, evidence coverage %, QA pass rate, last baseline date, last push date)
   - Register in src/server/routers/_app.ts

3. **Portfolio Dashboard page:**
   - New route: src/app/(dashboard)/workspace/[workspaceId]/portfolio/page.tsx
   - Add "Portfolio" link in workspace-level sidebar navigation
   - Summary cards at top: evidence coverage %, approval coverage %, QA pass rate, unresolved conflicts
   - **Coverage section:** bar chart of evidence coverage per project, approval coverage
   - **Volatility section:** change request volume over time (line chart), churn hotspot table
   - **Cycle time section:** three metric cards with average days, trend arrows
   - **Quality section:** QA pass rate trend line, top QA failures ranked list, ambiguous word trend
   - **Risk signals section:** red/amber flagged items (unresolved conflicts, low coverage packs, orphaned stories, stale sources) — each clickable to drill down
   - Date range filter (last 30/60/90 days, custom range)
   - Project filter (all or specific projects)
   - Use recharts for charts (already in package.json or add it)

4. **Tests:**
   - src/tests/server/services/portfolio-analytics.test.ts — test metric calculations with mocked data

Run pnpm verify when done.
```

### Test Before Moving On
- Does the portfolio dashboard load with real data from multiple projects?
- Do the charts render correctly?
- Can you filter by date range and see metrics change?
- Do risk signals correctly flag low-coverage packs and stale sources?
- Are cycle time metrics reasonable based on actual project timelines?

---

## Prompt 11: Methodology Overlays

**Branch:** `phase-6/story-S23.1-methodology-overlays`
**Commit prefix:** `feat(S23.1):`

### Context Files
- `prisma/schema.prisma` (Project, Template models)
- `src/server/routers/project.ts`
- `src/server/prompts/generation.ts`
- `src/server/services/generation.ts`

### Prompt — Copy into Cursor Composer

```
Read docs/BUILD_INSTRUCTIONS.md, docs/DATA_MODEL.md, and docs/PROMPT_STRATEGY.md first.

Add Methodology Overlays as a configurable layer on projects. A methodology defines the delivery framework conventions: terminology, artefact types, and workflow stages.

1. **Schema changes** — add to prisma/schema.prisma:

   model MethodologyConfig {
     id              String   @id @default(cuid())
     workspaceId     String
     name            String   // "Scrum", "Kanban", "PRINCE2", "ALIGN", "Custom"
     isBuiltIn       Boolean  @default(false) // true for system presets
     config          Json     // Full methodology configuration (see below)
     createdBy       String?
     createdAt       DateTime @default(now())
     updatedAt       DateTime @updatedAt

     @@index([workspaceId])
     @@unique([workspaceId, name])
   }

   Add to Project model:
   - methodologyId String?
   - methodology   MethodologyConfig? @relation(...)

   Run: npx prisma migrate dev --name add-methodology-overlays

2. **Methodology config JSON structure** (stored in config field):

   ```json
   {
     "artefactTypes": [
       { "key": "epic", "label": "Epic", "enabled": true },
       { "key": "story", "label": "User Story", "enabled": true },
       { "key": "nfr", "label": "Non-Functional Requirement", "enabled": true },
       { "key": "assumption", "label": "Assumption", "enabled": true },
       { "key": "risk", "label": "Risk", "enabled": true },
       { "key": "decision", "label": "Decision", "enabled": true },
       { "key": "product_description", "label": "Product Description", "enabled": false },
       { "key": "stakeholder_map", "label": "Stakeholder Map", "enabled": false },
       { "key": "influence_action", "label": "Influence Action", "enabled": false }
     ],
     "terminology": {
       "pack": "Story Pack",
       "baseline": "Baseline",
       "sprint": "Sprint"
     },
     "qaRuleOverrides": {
       "VAGUE_TERM": { "enabled": true },
       "UNTESTABLE": { "enabled": true }
     },
     "baselineLabelFormat": "Baseline v{N}",
     "workflowStages": ["draft", "in_review", "approved", "baselined"]
   }
   ```

3. **Built-in methodology presets** — create via seed or migration:
   - **Scrum**: uses Sprint terminology, story points field, sprint baselines, all standard artefact types
   - **Kanban**: continuous flow, no sprint boundaries, WIP limit setting on pack size, same artefact types
   - **PRINCE2**: stage gates, "Product Description" replaces "User Story", adds tolerance fields, baseline label "Stage Gate {N} Baseline"
   - **ALIGN**: adds "Stakeholder Map" artefact type (name, role alias, influence level, engagement strategy, evidence of commitment) and "Influence Action" artefact type (action, target stakeholder, Cialdini principle, outcome, evidence link). Adds a "Commitment Tracker" view.
   - **Custom**: user defines their own config

4. **Update generation prompts:**
   - In src/server/prompts/generation.ts and generation-system.ts:
     - Accept methodology config as parameter
     - Adjust the system prompt to use methodology terminology
     - Only request artefact types that are enabled in the config
     - For PRINCE2: prompt for "Product Description" format instead of user story format
     - For ALIGN: prompt for stakeholder maps and influence actions

5. **Methodology router** — add to src/server/routers/project.ts or new file:
   - `listMethodologies` query: all MethodologyConfigs for the workspace (built-in + custom)
   - `getProjectMethodology` query: current methodology for a project
   - `setProjectMethodology` mutation: assign a methodology to a project. Log to AuditLog.
   - `createCustomMethodology` mutation: create a custom config. Log to AuditLog.
   - `exportMethodology` query: return the config as JSON for import
   - `importMethodology` mutation: import a JSON config as a new custom methodology

6. **UI updates:**
   - Project settings: "Methodology" dropdown selector with preview of what changes
   - When methodology changes: show a confirmation dialog explaining the impact (which artefact types will be added/removed, QA rule changes, terminology changes)
   - Pack editor: UI labels update based on methodology terminology
   - QA rules: respect the methodology's qaRuleOverrides
   - Baseline labels: use the methodology's baselineLabelFormat
   - Export headings: use methodology-appropriate section titles

7. **ALIGN-specific views** (only visible when ALIGN methodology selected):
   - Stakeholder Map view: table of stakeholders with influence levels, engagement strategies
   - Commitment Tracker: list of all stakeholder commitments extracted from sources, with fulfilment status
   - These are generated by the AI alongside standard artefacts when ALIGN is selected

8. **Tests:**
   - src/tests/server/services/methodology.test.ts — test config loading, artefact type filtering, terminology substitution
   - Test that PRINCE2 prompt generates Product Descriptions, not User Stories
   - Test that ALIGN prompt generates Stakeholder Maps

Run pnpm verify when done.
```

### Test Before Moving On
- Can you set a project to use PRINCE2 and generate a pack with Product Descriptions?
- Does ALIGN methodology produce Stakeholder Map artefacts?
- Can you create a custom methodology and assign it to a project?
- Do QA rules respect the methodology overrides?
- Does the terminology update throughout the UI?

---

## Prompt 12: Enterprise Compliance — Legal Hold, Compliance Export, Session Management

**Branch:** `phase-6/story-S24.1-enterprise-compliance`
**Commit prefix:** `feat(S24.1):`

### Context Files
- `prisma/schema.prisma`
- `src/server/routers/workspace.ts`
- `src/server/services/retention.ts` (from Prompt 9)
- `src/server/services/audit.ts`

### Prompt — Copy into Cursor Composer

```
Read docs/BUILD_INSTRUCTIONS.md and docs/DATA_MODEL.md first.

Add enterprise compliance features: legal hold, compliance export, session management, and SSO preparation UI.

1. **Schema changes** — add to prisma/schema.prisma:

   Add to Project model:
   - legalHold        Boolean @default(false)
   - legalHoldSetBy   String?
   - legalHoldSetAt   DateTime?

   Add to Workspace model:
   - sessionTimeoutHours Int @default(8)
   - dataRegion          String @default("eu-west-1")
   - ssoEnabled          Boolean @default(false)
   - ssoProvider         String? // "saml" or "oidc"
   - ssoMetadataUrl      String?
   - ssoEntityId         String?

   Run: npx prisma migrate dev --name add-compliance-features

2. **Legal hold enforcement:**
   - Update ALL mutation middlewares that delete or modify sources, baselines, or evidence:
     - Before delete/modify: check project.legalHold
     - If true: throw TRPCError("FORBIDDEN", "This project is under legal hold. Deletion and modification of sources and baselines is restricted.")
   - Legal hold does NOT prevent: viewing, commenting, exporting, or creating new content
   - Only workspace Admin can set/remove legal hold

3. **Compliance export service** — new file src/server/services/compliance-export.ts:
   - Export async function generateComplianceExport(workspaceId: string): Promise<Buffer>
   - Generates a ZIP containing:
     - projects/ — subdirectory per project with: sources, evidence, packs, baselines (all as JSON)
     - audit-log.csv — complete workspace audit log
     - access-records.csv — all WorkspaceMember and ProjectMember records with: userId, role, assignedAt, removedAt
     - approval-records.csv — all ApprovalRequest records with timestamps and signatures
     - retention-policy.json — current retention settings
     - manifest.json — { exportedAt, workspaceId, fileList, sha256Hashes, totalProjects, totalUsers }
   - Hash each file with SHA-256 for integrity verification

4. **Compliance router** — add to workspace router or new file src/server/routers/compliance.ts:
   - `setLegalHold` mutation: toggle legal hold on a project (Admin only). Log to AuditLog.
   - `removeLegalHold` mutation: remove legal hold (Admin only). Log to AuditLog.
   - `generateComplianceExport` mutation: trigger the ZIP generation, return download URL. Log to AuditLog.
   - `getComplianceStatus` query: return { legalHolds: Project[], retentionPolicy, ssoStatus, sessionTimeout, dataRegion, lastComplianceExport }
   - Register in src/server/routers/_app.ts

5. **Session management:**
   - This is informational for now since Clerk manages sessions
   - Show active sessions info from Clerk's user metadata
   - "Sign out all other sessions" button (calls Clerk's session revocation API if available, otherwise show instructional text)
   - Session timeout display (configurable per workspace, enforced by Clerk JWT expiry)

6. **SSO preparation UI:**
   - In workspace settings, add "Single Sign-On" section
   - Form fields: SSO provider dropdown (SAML/OIDC), metadata URL, entity ID, certificate upload
   - All fields save to the Workspace model but display a "Coming soon — contact sales@synqforge.com" banner
   - Same approach for SCIM provisioning: UI shell with "coming soon" message
   - Build the data model so it's ready for implementation

7. **Security & Compliance page:**
   - New settings sub-page: src/app/(dashboard)/workspace/[workspaceId]/settings/compliance/page.tsx
   - Dashboard showing all active controls:
     - Retention policy status (enabled/disabled, days)
     - Legal holds: list of projects under hold
     - SSO status: not configured / coming soon
     - Session timeout: current setting
     - Data region: current region display
     - Last compliance export: date and "Export Now" button
   - All sections with clear status indicators

8. **Tests:**
   - src/tests/server/services/compliance-export.test.ts — verify ZIP structure and manifest hashes
   - src/tests/server/middleware/legal-hold.test.ts — verify deletion is blocked under legal hold
   - Test that legal hold doesn't prevent read operations

Run pnpm verify when done.
```

### Test Before Moving On
- Activate legal hold on a project — is deletion of sources and baselines blocked?
- Does legal hold allow viewing, commenting, and exporting?
- Does the compliance export ZIP contain all expected sections with SHA-256 hashes?
- Does the Security & Compliance page show all controls correctly?
- Does the SSO section display the "coming soon" message with the form shell?

---

## Post-Build Verification Checklist

After completing all 12 prompts, run through this validation:

**Core Pipeline:**
- [ ] Export a pack in all four formats (DOCX, CSV, HTML, JSON)
- [ ] View the Evidence Ledger with classification tags and search
- [ ] Trigger conflict detection between contradicting sources
- [ ] Complete a full approval workflow with typed signature
- [ ] Create a baseline, edit stories, create second baseline, compare diffs
- [ ] Upload a new source version, see auto-generated Change Request

**Integrations:**
- [ ] Push to Monday.com, edit a story, see "changed since push" flag
- [ ] Re-push changed stories and verify existing items are updated

**Governance:**
- [ ] Assign project roles and verify permission enforcement
- [ ] Set retention policies and verify auto-archive
- [ ] Activate legal hold and confirm deletions are blocked
- [ ] Generate compliance export ZIP and verify manifest hashes

**Enterprise:**
- [ ] View portfolio analytics with real cross-project data
- [ ] Set a project to PRINCE2 methodology and generate a pack
- [ ] Set a project to ALIGN and verify Stakeholder Map artefacts
- [ ] View Security & Compliance dashboard with all controls

**Final Check:**
```bash
pnpm verify  # Must pass: lint + typecheck + test + build
```
